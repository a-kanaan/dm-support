{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85826a80-a9f8-44b8-90aa-a5ef0d3534d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e63b56-cf77-4af6-bcbd-13f01f834b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: 'Dear customer, congratulations! You've won a free trip to an exotic destination. it is urgent to respond soon' is classified as 'spam'.\n",
      "Email: 'Hello, I hope you're doing well. Let's catch up soon.' is classified as 'ham'.\n",
      "Email: 'Limited time offer: Get a 50% discount on our latest products! act now!' is classified as 'spam'.\n",
      "Email: 'Reminder: Your payment is due by tomorrow. Please urgent limited time, act now.' is classified as 'spam'.\n",
      "Email: 'Hi, just wanted to share an interesting article I came across.' is classified as 'ham'.\n"
     ]
    }
   ],
   "source": [
    "# Define a list of predefined rules for classifying emails\n",
    "spam_keywords = ['free', 'soon', 'discount', 'limited time', 'urgent', 'act now']\n",
    "spam_threshold = 3  # Minimum number of spam keywords required for an email to be classified as spam\n",
    "\n",
    "# Function to classify an email as \"ham\" or \"spam\" based on predefined rules\n",
    "def classify_email(email_content):\n",
    "    # Convert email content to lowercase for case-insensitive matching\n",
    "    email_content = email_content.lower()\n",
    "    \n",
    "    # Check for the presence of spam keywords in the email content\n",
    "    spam_count = sum(keyword in email_content for keyword in spam_keywords)\n",
    "    \n",
    "    # Apply the classification rule\n",
    "    if spam_count >= spam_threshold:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'\n",
    "\n",
    "# Sample data - emails to be classified\n",
    "emails = [\n",
    "    \"Dear customer, congratulations! You've won a free trip to an exotic destination. it is urgent to respond soon\",\n",
    "    \"Hello, I hope you're doing well. Let's catch up soon.\",\n",
    "    \"Limited time offer: Get a 50% discount on our latest products! act now!\",\n",
    "    \"Reminder: Your payment is due by tomorrow. Please urgent limited time, act now.\",\n",
    "    \"Hi, just wanted to share an interesting article I came across.\",\n",
    "]\n",
    "\n",
    "# Classify each email using the classify_email function\n",
    "for email in emails:\n",
    "    classification = classify_email(email)\n",
    "    print(f\"Email: '{email}' is classified as '{classification}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4970a07a-7d34-41ca-b1ad-850f511655eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: 'Dear customer, congratulations! You've won a free trip to an exotic destination. it is urgent to respond soon.' is classified as 'spam'.\n",
      "Email: 'Hello, I hope you're doing well. Let's catch up soon.' is classified as 'ham'.\n",
      "Email: 'Limited time offer: Get a 50% discount on our latest products! act now!' is classified as 'spam'.\n",
      "Email: 'Reminder: Your payment is due by tomorrow. Please urgent limited time, act now.' is classified as 'spam'.\n",
      "Email: 'Hi, just wanted to share an interesting article I came across.' is classified as 'ham'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Sample data - emails and their corresponding labels\n",
    "emails = [\n",
    "    (\"Dear customer, congratulations! You've won a free trip to an exotic destination. it is urgent to respond soon.\", \"spam\"),\n",
    "    (\"Hello, I hope you're doing well. Let's catch up soon.\", \"ham\"),\n",
    "    (\"Limited time offer: Get a 50% discount on our latest products! act now!\", \"spam\"),\n",
    "    (\"Reminder: Your payment is due by tomorrow. Please urgent limited time, act now.\", \"spam\"),\n",
    "    (\"Hi, just wanted to share an interesting article I came across.\", \"ham\"),\n",
    "]\n",
    "\n",
    "# Convert the sample data to a pandas DataFrame\n",
    "df = pd.DataFrame(emails, columns=[\"email\", \"label\"])\n",
    "\n",
    "# Extract features from the email text using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"email\"])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Naive Bayes classifier on the training data\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Classify the test emails using the trained classifier\n",
    "y_pred = classifier.predict(X)\n",
    "\n",
    "# Print the predicted labels for the test emails\n",
    "for i, email in enumerate(df[\"email\"]):\n",
    "    print(f\"Email: '{email}' is classified as '{y_pred[i]}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d03317eb-e664-405a-a2a3-d774f2ba3f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000020A647B1040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000020A647B1040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.2000WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000020A53D70D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000020A53D70D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.6940 - accuracy: 0.2000 - val_loss: 0.6873 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6873 - accuracy: 0.8000 - val_loss: 0.6802 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6802 - accuracy: 0.8000 - val_loss: 0.6720 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6720 - accuracy: 0.8000 - val_loss: 0.6619 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6619 - accuracy: 0.8000 - val_loss: 0.6490 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6490 - accuracy: 0.8000 - val_loss: 0.6326 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6326 - accuracy: 0.8000 - val_loss: 0.6114 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6114 - accuracy: 0.8000 - val_loss: 0.5840 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5840 - accuracy: 1.0000 - val_loss: 0.5490 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5490 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5046 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4496 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3833 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3062 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1427 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a53dd2d00>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "\n",
    "# Sample data - emails and their corresponding labels\n",
    "emails = [\n",
    "    (\"Dear customer, congratulations! You've won a free trip to an exotic destination. it is urgent to respond soon.\", \"spam\"),\n",
    "    (\"Hello, I hope you're doing well. Let's catch up soon.\", \"ham\"),\n",
    "    (\"Limited time offer: Get a 50% discount on our latest products! act now!\", \"spam\"),\n",
    "    (\"Reminder: Your payment is due by tomorrow. Please urgent limited time, act now.\", \"spam\"),\n",
    "    (\"Hi, just wanted to share an interesting article I came across.\", \"ham\"),\n",
    "]\n",
    "\n",
    "# Convert the sample data to a pandas DataFrame\n",
    "df = pd.DataFrame(emails, columns=[\"email\", \"label\"])\n",
    "\n",
    "# Preprocess the data\n",
    "X = df[\"email\"].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0, random_state=42)\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "# Tokenize and pad the email text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "#X_test = tokenizer.texts_to_sequences(X_test)\n",
    "max_sequence_length = max(len(seq) for seq in X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "#X_test = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, validation_data=(X_train, y_train), epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "798f4919-9f26-4840-b96c-824507a17923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "Email: Dear customer, congratulations! You've won a free trip to an exotic destination. it is urgent to respond soon.  is classified as spam.\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Email: Hello, I hope you're doing well. Let's catch up soon.  is classified as ham.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Email: Limited time offer: Get a 50% discount on our latest products! act now!  is classified as spam.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Email: Reminder: Your payment is due by tomorrow. Please urgent limited time, act now.  is classified as spam.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Email: Hi, just wanted to share an interesting article I came across.  is classified as ham.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i, email in enumerate(X_train):\n",
    "    predicted_result= model.predict(np.expand_dims(email, axis=0))\n",
    "    print(f'Email: {X[i]}  is classified as {\"ham\" if predicted_result < 0.5 else \"spam\"}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba2d4efd-26b2-49d0-9c47-13f7e45f2f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Test Loss: 0.0108\n",
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7cb53-0f5b-411b-8eff-4b37175d364a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eocv",
   "language": "python",
   "name": "eocv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
